**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report #3 – Code Coverage, Adequacy Criteria and Test Case Correlation**

| Group \#:      |  25   |
| -------------- | --- |
| Student Names: | Sahil Bhatt    |
|                | Harshal Patel   |
|                | Siwon Kim    |
|                | Abhiraam Manchiraju    |

(Note that some labs require individual reports while others require one report
for each group. Please see each lab document for details.)

# 1 Introduction

In this lab we will once again be performing unit testing using JUnit in Eclipse. However, contrasting the previous assignment, we will be utilizing white-box coverage criteria testing, rather than blackbox testing. The same system, JFreeChart, will be the system under test.

The objective of this lab is to be introduced to white-box suite testing, and determining its adequacy based on the coverage of the code. We will learn how to measure test adequacy, design test cases to improve code coverage, understand the pros and cons of using code coverage tools to measure test adequacy, and understand how data-flow coverage works.

# 2 Manual data-flow coverage calculations for X and Y methods

## **calculateColumnTotal()**

### **Data Flow Diagram**

![DataFlowDiagram1.png](media/DataFlowDiagram1.png)

### **Def-Use Sets**

|Statement(Node) | def(n)           | c-use(n)       | p-use(n)    | 
|----------------|------------------|----------------|-------------|
|1               |{data,column}     |{}              |{data}       |
|2               |{total,rowCount,r}|{}              |{data}       | 
|3               |{}                |{}              |{r,rowCount} | 
|4               |{n}               |{r,data,column} |{n}          | 
|5               |{total}           |{total,n}       |{}           |
|6               |{r}               |{r}             |{}           | 
|7               |{r2}              |{}              |{}           | 
|8               |{}                |{}              |{r2,rowCount}|
|9               |{n}               |{r2,data,column}|{n}          |
|10              |{total}           |{total,n}       |{}           |
|11              |{r2}              |{r2}            |{}           |
|12              |{}                |{total}         |{}           |

### **DU Pairs Per Variable**
- data: (1,1) (1,2) (1,4) (1,9)

- column: (1,4) (1,9)

- total: (2,5) (2,10) (2,12)

- r: (2,3) (2,4) (2,6) (6,3)

- rowCount: (2,3) (2,8)

- n: (4,4) (4,5) (9,9) (9,10)

- r2: (7,8), (7,9) (7,11) (11,8)


### **DU Pairs Covered per Test**
- calculateColumnTotalForPositiveNumbers() ->  (1,1) (1,2) (1,4,data) (1,4,column) (2,5) (2,12) (2,3,r) (2,3,rowCount) (2,4) (2,6) (6,3) (4,4) (4,5) (2,8) (7,8)

- calculateColumnTotalForNegativeNumbers() -> (1,1) (1,2) (1,4,data) (1,4,column) (2,5) (2,12) (2,3,r) (2,3,rowCount) (2,4) (2,6) (6,3) (4,4) (4,5) (2,8) (7,8)

- calculateColumnTotalForNegativeAndPositiveNumbers() -> (1,1) (1,2) (1,4,data) (1,4,column) (2,5) (2,12) (2,3,r) (2,3,rowCount) (2,4) (2,6) (6,3) (4,4) (4,5) (2,8) (7,8)

- calculateColumnTotalForFourRows() -> (1,1) (1,2) (1,4,data) (1,4,column) (2,5) (2,12) (2,3,r) (2,3,rowCount) (2,4) (2,6) (6,3) (4,4) (4,5) (2,8) (7,8)


### **DU Pair Coverage**

Coverage = DU Pairs Covered / (Total DU Pairs - Infeasible DU Pairs) * 100%

Coverage = 15 / (23 - 8) * 100% = 100%

 <br>  

## **contains()**

### **Data Flow Diagram**
![DataFlowGraph2.png](media/DataFlowDiagram2.png)

### **Def-Use Sets**

|Statement(Node) | def(n)           | c-use(n)       | p-use(n)    | 
|----------------|------------------|----------------|-------------|
|1               |{value}           |{}              |{value}      |
|2               |{}                |{}              |{value}      | 
|3               |{}                |{}              |{value}      | 

### **DU Pairs Per Variable**
- value: (1,1) (1,2) (1,3)

### **DU Pairs Covered per Test**
- containsWithinBounds() -> (1,1) (1,2) (1,3)

- containsOutOfLowerBound() -> (1,1)

- containsOutOfUpperBound() -> (1,1) (1,2)

- containsAtLowerBound() -> (1,1) (1,2) (1,3)

- containsAtUpperBound() -> (1,1) (1,2) (1,3)

### **DU Pair Coverage**

Coverage = DU Pairs Covered / (Total DU Pairs - Infeasible DU Pairs) * 100%

Coverage = 3 / (3 - 0) * 100% = 100%


# 3 A detailed description of the testing strategy for the new unit test

Text…

# 4 A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage

Text…

# 5 A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)

## **Initial Coverage**
**DataUtilities.java**
- Line: 45.8%
- Branch: 29.7%
- Method: 50%

**Range.java**
- Line: 32.8%
- Branch: 34.1%
- Method: 43.5%

## **Final Coverage**
**DataUtilities.java**

Line Coverage

![DataFlowDiagram1.png](media/DataLineCoverage.png)

Branch Coverage

![DataFlowDiagram1.png](media/DataBranchCoverage.png)

Method Coverage

![DataFlowDiagram1.png](media/DataMethodCoverage.png)

 <br>  

**Range.java**

Line Coverage

![DataFlowDiagram1.png](media/RangeLineCoverage.png)

Branch Coverage

![DataFlowDiagram1.png](media/RangeBranchCoverage.png)

Method Coverage

![DataFlowDiagram1.png](media/RangeMethodCoverage.png)

**Note** 


For DataUtilities.java, we were not able to achieve 90% line coverage and instead achieved 88.5%. This is due to sections of code in several methods that were unreachable/unfeasible. Some of examples of this include calculateColumnTotal(Values2D data, int column), calculateRowTotal(Values2D data, int row) and getCumulativePercentages(KeyedValues data) where both of these methods had an extra for loop that was simply unreachable. 


# 6 Pros and Cons of coverage tools used and Metrics you report

For our testing tool we chose to use EcLEmma to track the amount of code that was covered. The reason that we chose EclEmma was because it was a tool that integrated with Eclipse, and setting it up was very easy. The tool was also easy to run, and similar to how we would use junit, where we would simply run the file using the EclEmma tool. Once the tool was run, we would see the percentage of code that would be covered from the tests. There were different types of coverage you could also toggle, which included, instruction, method, line, branch, method, type, complexity. This was helpful to see the coverage depending on these factors. We also were able to see the coverage of different method in a particular class which was helpful when increasing coverage for that method. Eclemma has great user friendliness, due to the simplicity of it. The tool also did not crash. One disadvantage of the tool was that it provides the coverage of the test file itself along with the class. This was a little confusing when determining what the coverage was as we got two different percentages of coverages. Another disadvantage is the documentation, as it would’ve been helpful if there was better documentation of the tool, as some of the features we had to figure out. 

# 7 A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation.

Text…

# 8 A discussion on how the team work/effort was divided and managed

Text…

# 9 Any difficulties encountered, challenges overcome, and lessons learned from performing the lab

Text…

# 10 Comments/feedback on the lab itself

Text…
